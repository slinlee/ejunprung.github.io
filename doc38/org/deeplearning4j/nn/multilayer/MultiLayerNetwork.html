<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (version 1.7.0_60) on Wed Jan 13 15:16:45 PST 2016 -->
<title>MultiLayerNetwork</title>
<meta name="date" content="2016-01-13">
<link rel="stylesheet" type="text/css" href="../../../../stylesheet.css" title="Style">
</head>
<body>
<script type="text/javascript"><!--
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="MultiLayerNetwork";
    }
//-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar_top">
<!--   -->
</a><a href="#skip-navbar_top" title="Skip navigation links"></a><a name="navbar_top_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-files/index-1.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/deeplearning4j/nn/multilayer/GravesLSTMOutputTest.html" title="class in org.deeplearning4j.nn.multilayer"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerTest.html" title="class in org.deeplearning4j.nn.multilayer"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html" target="_top">Frames</a></li>
<li><a href="MultiLayerNetwork.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li><a href="#field_summary">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li><a href="#field_detail">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.deeplearning4j.nn.multilayer</div>
<h2 title="Class MultiLayerNetwork" class="title">Class MultiLayerNetwork</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>java.lang.Object</li>
<li>
<ul class="inheritance">
<li>org.deeplearning4j.nn.multilayer.MultiLayerNetwork</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>All Implemented Interfaces:</dt>
<dd>java.io.Serializable, java.lang.Cloneable, <a href="../../../../org/deeplearning4j/nn/api/Classifier.html" title="interface in org.deeplearning4j.nn.api">Classifier</a>, <a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>, <a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></dd>
</dl>
<hr>
<br>
<pre>public class <span class="strong">MultiLayerNetwork</span>
extends java.lang.Object
implements java.io.Serializable, <a href="../../../../org/deeplearning4j/nn/api/Classifier.html" title="interface in org.deeplearning4j.nn.api">Classifier</a>, <a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></pre>
<div class="block">A base class for a multi
 layer neural network with a logistic output layer
 and multiple hidden neuralNets.</div>
<dl><dt><span class="strong">See Also:</span></dt><dd><a href="../../../../serialized-form.html#org.deeplearning4j.nn.multilayer.MultiLayerNetwork">Serialized Form</a></dd></dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== NESTED CLASS SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="nested_class_summary">
<!--   -->
</a>
<h3>Nested Class Summary</h3>
<ul class="blockList">
<li class="blockList"><a name="nested_classes_inherited_from_class_org.deeplearning4j.nn.api.Layer">
<!--   -->
</a>
<h3>Nested classes/interfaces inherited from interface&nbsp;org.deeplearning4j.nn.api.<a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></h3>
<code><a href="../../../../org/deeplearning4j/nn/api/Layer.TrainingMode.html" title="enum in org.deeplearning4j.nn.api">Layer.TrainingMode</a>, <a href="../../../../org/deeplearning4j/nn/api/Layer.Type.html" title="enum in org.deeplearning4j.nn.api">Layer.Type</a></code></li>
</ul>
</li>
</ul>
<!-- =========== FIELD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="field_summary">
<!--   -->
</a>
<h3>Field Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Field Summary table, listing fields, and an explanation">
<caption><span>Fields</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Field and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected <a href="../../../../org/deeplearning4j/nn/conf/NeuralNetConfiguration.html" title="class in org.deeplearning4j.nn.conf">NeuralNetConfiguration</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#defaultConfiguration">defaultConfiguration</a></strong></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected <a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#gradient">gradient</a></strong></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#initCalled">initCalled</a></strong></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected INDArray</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#input">input</a></strong></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected INDArray</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#labels">labels</a></strong></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected int</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#layerIndex">layerIndex</a></strong></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected java.util.LinkedHashMap&lt;java.lang.String,<a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#layerMap">layerMap</a></strong></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected <a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>[]</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#layers">layers</a></strong></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected <a href="../../../../org/deeplearning4j/nn/conf/MultiLayerConfiguration.html" title="class in org.deeplearning4j.nn.conf">MultiLayerConfiguration</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#layerWiseConfigurations">layerWiseConfigurations</a></strong></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected INDArray</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#mask">mask</a></strong></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected double</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#score">score</a></strong></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected <a href="../../../../org/deeplearning4j/optimize/Solver.html" title="class in org.deeplearning4j.optimize">Solver</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#solver">solver</a></strong></code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Constructor Summary table, listing constructors, and an explanation">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">Constructor and Description</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#MultiLayerNetwork(org.deeplearning4j.nn.conf.MultiLayerConfiguration)">MultiLayerNetwork</a></strong>(<a href="../../../../org/deeplearning4j/nn/conf/MultiLayerConfiguration.html" title="class in org.deeplearning4j.nn.conf">MultiLayerConfiguration</a>&nbsp;conf)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colOne"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#MultiLayerNetwork(org.deeplearning4j.nn.conf.MultiLayerConfiguration,%20INDArray)">MultiLayerNetwork</a></strong>(<a href="../../../../org/deeplearning4j/nn/conf/MultiLayerConfiguration.html" title="class in org.deeplearning4j.nn.conf">MultiLayerConfiguration</a>&nbsp;conf,
                 INDArray&nbsp;params)</code>
<div class="block">Initialize the network based on the configuraiton</div>
</td>
</tr>
<tr class="altColor">
<td class="colOne"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#MultiLayerNetwork(java.lang.String,%20INDArray)">MultiLayerNetwork</a></strong>(java.lang.String&nbsp;conf,
                 INDArray&nbsp;params)</code>
<div class="block">Initialize the network based on the configuration</div>
</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method_summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span>Methods</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#accumulateScore(double)">accumulateScore</a></strong>(double&nbsp;accum)</code>
<div class="block">Sets a rolling tally for the score.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>INDArray</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#activate()">activate</a></strong>()</code>
<div class="block">Triggers the activation of the last hidden layer ie: not logistic regression</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>INDArray</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#activate(boolean)">activate</a></strong>(boolean&nbsp;training)</code>
<div class="block">Trigger an activation with the last specified input</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>INDArray</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#activate(INDArray)">activate</a></strong>(INDArray&nbsp;input)</code>
<div class="block">Trigger an activation with the last specified input</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>INDArray</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#activate(INDArray,%20boolean)">activate</a></strong>(INDArray&nbsp;input,
        boolean&nbsp;training)</code>
<div class="block">Initialize the layer with the given input
 and return the activation for this layer
 given this input</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>INDArray</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#activate(INDArray,%20org.deeplearning4j.nn.api.Layer.TrainingMode)">activate</a></strong>(INDArray&nbsp;input,
        <a href="../../../../org/deeplearning4j/nn/api/Layer.TrainingMode.html" title="enum in org.deeplearning4j.nn.api">Layer.TrainingMode</a>&nbsp;training)</code>
<div class="block">Initialize the layer with the given input
 and return the activation for this layer
 given this input</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>INDArray</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#activate(int)">activate</a></strong>(int&nbsp;layer)</code>
<div class="block">Triggers the activation for a given layer</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>INDArray</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#activate(int,%20INDArray)">activate</a></strong>(int&nbsp;layer,
        INDArray&nbsp;input)</code>
<div class="block">Triggers the activation of the given layer</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>INDArray</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#activate(org.deeplearning4j.nn.api.Layer.TrainingMode)">activate</a></strong>(<a href="../../../../org/deeplearning4j/nn/api/Layer.TrainingMode.html" title="enum in org.deeplearning4j.nn.api">Layer.TrainingMode</a>&nbsp;training)</code>
<div class="block">Trigger an activation with the last specified input</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>INDArray</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#activateSelectedLayers(int,%20int,%20INDArray)">activateSelectedLayers</a></strong>(int&nbsp;from,
                      int&nbsp;to,
                      INDArray&nbsp;input)</code>
<div class="block">Calculate activation for few layers at once.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>INDArray</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#activationFromPrevLayer(int,%20INDArray,%20boolean)">activationFromPrevLayer</a></strong>(int&nbsp;curr,
                       INDArray&nbsp;input,
                       boolean&nbsp;training)</code>
<div class="block">Calculate activation from previous layer including pre processing where necessary</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>INDArray</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#activationMean()">activationMean</a></strong>()</code>
<div class="block">Calculate the mean representation
 for the activation for this layer</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#applyLearningRateScoreDecay()">applyLearningRateScoreDecay</a></strong>()</code>
<div class="block">Update learningRate using for this model.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#backprop()">backprop</a></strong>()</code>
<div class="block">Calculate and set gradients for MultiLayerNetwork, based on OutputLayer and labels</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>,INDArray&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#backpropGradient(INDArray)">backpropGradient</a></strong>(INDArray&nbsp;epsilon)</code>
<div class="block">Calculate the gradient relative to the error in the next layer</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected java.util.List&lt;<a href="../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;<a href="../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;INDArray,INDArray&gt;,<a href="../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;INDArray,INDArray&gt;&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#backPropGradient2()">backPropGradient2</a></strong>()</code>
<div class="block">Do a back prop iteration.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected java.util.List&lt;<a href="../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;INDArray,INDArray&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#backPropGradientR(INDArray)">backPropGradientR</a></strong>(INDArray&nbsp;v)</code>
<div class="block">Do a back prop iteration.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#batchSize()">batchSize</a></strong>()</code>
<div class="block">The current inputs batch size</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected <a href="../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>,INDArray&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#calcBackpropGradients(INDArray,%20boolean)">calcBackpropGradients</a></strong>(INDArray&nbsp;epsilon,
                     boolean&nbsp;withOutputLayer)</code>
<div class="block">Calculate gradients and errors.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#calcGradient(org.deeplearning4j.nn.gradient.Gradient,%20INDArray)">calcGradient</a></strong>(<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>&nbsp;layerError,
            INDArray&nbsp;activation)</code>
<div class="block">Calculate the gradient</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#calcL1()">calcL1</a></strong>()</code>
<div class="block">Calculate the l1 regularization term<br>
 0.0 if regularization is not used.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#calcL2()">calcL2</a></strong>()</code>
<div class="block">Calculate the l2 regularization term<br>
 0.0 if regularization is not used.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#clear()">clear</a></strong>()</code>
<div class="block">Clear the inputs.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#clearLayerMaskArrays()">clearLayerMaskArrays</a></strong>()</code>
<div class="block">Remove the mask arrays from all layers.<br>
 See <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setLayerMaskArrays(INDArray,%20INDArray)"><code>setLayerMaskArrays(INDArray, INDArray)</code></a> for details on mask arrays.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html" title="class in org.deeplearning4j.nn.multilayer">MultiLayerNetwork</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#clone()">clone</a></strong>()</code>
<div class="block">Clone the layer</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected java.util.List&lt;<a href="../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;INDArray,INDArray&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#computeDeltas2()">computeDeltas2</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected java.util.List&lt;INDArray&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#computeDeltasR(INDArray)">computeDeltasR</a></strong>(INDArray&nbsp;v)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#computeGradientAndScore()">computeGradientAndScore</a></strong>()</code>
<div class="block">Update the score</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>java.util.List&lt;INDArray&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#computeZ(boolean)">computeZ</a></strong>(boolean&nbsp;training)</code>
<div class="block">* Compute input linear transformation (z) of the output layer</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>java.util.List&lt;INDArray&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#computeZ(INDArray,%20boolean)">computeZ</a></strong>(INDArray&nbsp;input,
        boolean&nbsp;training)</code>
<div class="block">Compute activations from input to output of the output layer</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/conf/NeuralNetConfiguration.html" title="class in org.deeplearning4j.nn.conf">NeuralNetConfiguration</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#conf()">conf</a></strong>()</code>
<div class="block">The configuration for the neural network</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#dampingUpdate(double,%20double,%20double)">dampingUpdate</a></strong>(double&nbsp;rho,
             double&nbsp;boost,
             double&nbsp;decrease)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>INDArray</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#derivativeActivation(INDArray)">derivativeActivation</a></strong>(INDArray&nbsp;input)</code>
<div class="block">Take the derivative of the given input
 based on the activation</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#doTruncatedBPTT(INDArray,%20INDArray)">doTruncatedBPTT</a></strong>(INDArray&nbsp;input,
               INDArray&nbsp;labels)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#error(INDArray)">error</a></strong>(INDArray&nbsp;errorSignal)</code>
<div class="block">Calculate error with respect to the
 current layer.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#f1Score(INDArray,%20INDArray)">f1Score</a></strong>(INDArray&nbsp;input,
       INDArray&nbsp;labels)</code>
<div class="block">Sets the input and labels and returns a score for the prediction
 wrt true labels</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#f1Score(org.nd4j.linalg.dataset.api.DataSet)">f1Score</a></strong>(org.nd4j.linalg.dataset.api.DataSet&nbsp;data)</code>
<div class="block">Sets the input and labels and returns a score for the prediction
 wrt true labels</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>java.util.List&lt;INDArray&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#feedForward()">feedForward</a></strong>()</code>
<div class="block">Compute activations from input to output of the output layer</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>java.util.List&lt;INDArray&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#feedForward(boolean)">feedForward</a></strong>(boolean&nbsp;train)</code>
<div class="block">Compute activations from input to output of the output layer</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>java.util.List&lt;INDArray&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#feedForward(INDArray)">feedForward</a></strong>(INDArray&nbsp;input)</code>
<div class="block">Compute activations from input to output of the output layer</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>java.util.List&lt;INDArray&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#feedForward(INDArray,%20boolean)">feedForward</a></strong>(INDArray&nbsp;input,
           boolean&nbsp;train)</code>
<div class="block">Compute activations from input to output of the output layer</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>java.util.List&lt;INDArray&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#feedForward(INDArray,%20INDArray,%20INDArray)">feedForward</a></strong>(INDArray&nbsp;input,
           INDArray&nbsp;featuresMask,
           INDArray&nbsp;labelsMask)</code>
<div class="block">Compute the activations from the input to the output layer, given mask arrays (that may be null)
 The masking arrays are used in situations such an one-to-many and many-to-one rucerrent neural network (RNN)
 designs, as well as for supporting time series of varying lengths within the same minibatch for RNNs.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;java.util.List&lt;INDArray&gt;,java.util.List&lt;INDArray&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#feedForwardActivationsAndDerivatives(boolean)">feedForwardActivationsAndDerivatives</a></strong>(boolean&nbsp;training)</code>
<div class="block">Compute input linear transformation (z)
 Compute activations (applies activation transformation to z)</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>java.util.List&lt;INDArray&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#feedForwardR(java.util.List,%20INDArray)">feedForwardR</a></strong>(java.util.List&lt;INDArray&gt;&nbsp;acts,
            INDArray&nbsp;v)</code>
<div class="block">Feed forward with the r operator</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>java.util.List&lt;INDArray&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#feedForwardToLayer(int,%20boolean)">feedForwardToLayer</a></strong>(int&nbsp;layerNum,
                  boolean&nbsp;train)</code>
<div class="block">Compute the activations from the input to the specified layer, using the currently set input for the network.<br>
 To compute activations for all layers, use feedForward(...) methods<br>
 Note: output list includes the original input.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>java.util.List&lt;INDArray&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#feedForwardToLayer(int,%20INDArray)">feedForwardToLayer</a></strong>(int&nbsp;layerNum,
                  INDArray&nbsp;input)</code>
<div class="block">Compute the activations from the input to the specified layer.<br>
 To compute activations for all layers, use feedForward(...) methods<br>
 Note: output list includes the original input.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>java.util.List&lt;INDArray&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#feedForwardToLayer(int,%20INDArray,%20boolean)">feedForwardToLayer</a></strong>(int&nbsp;layerNum,
                  INDArray&nbsp;input,
                  boolean&nbsp;train)</code>
<div class="block">Compute the activations from the input to the specified layer.<br>
 To compute activations for all layers, use feedForward(...) methods<br>
 Note: output list includes the original input.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#finetune()">finetune</a></strong>()</code>
<div class="block">Run SGD based on the given labels</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#fit()">fit</a></strong>()</code>
<div class="block">All models have a fit method</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#fit(DataSetIterator)">fit</a></strong>(DataSetIterator&nbsp;iter)</code>
<div class="block">Train the model based on the datasetiterator</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#fit(INDArray)">fit</a></strong>(INDArray&nbsp;data)</code>
<div class="block">Fit the unsupervised model</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#fit(INDArray,%20INDArray)">fit</a></strong>(INDArray&nbsp;data,
   INDArray&nbsp;labels)</code>
<div class="block">Fit the model</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#fit(INDArray,%20int[])">fit</a></strong>(INDArray&nbsp;examples,
   int[]&nbsp;labels)</code>
<div class="block">Fit the model</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#fit(org.nd4j.linalg.dataset.api.DataSet)">fit</a></strong>(org.nd4j.linalg.dataset.api.DataSet&nbsp;data)</code>
<div class="block">Fit the model</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;INDArray,INDArray&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getBackPropGradient2()">getBackPropGradient2</a></strong>()</code>
<div class="block">Gets the back prop gradient with the r operator (gauss vector)
 and the associated precon matrix
 This is also called computeGV</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>INDArray</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getBackPropRGradient(INDArray)">getBackPropRGradient</a></strong>(INDArray&nbsp;v)</code>
<div class="block">Gets the back prop gradient with the r operator (gauss vector)
 This is also called computeGV</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/conf/NeuralNetConfiguration.html" title="class in org.deeplearning4j.nn.conf">NeuralNetConfiguration</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getDefaultConfiguration()">getDefaultConfiguration</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getIndex()">getIndex</a></strong>()</code>
<div class="block">Get the layer index.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>INDArray</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getInput()">getInput</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getInputMiniBatchSize()">getInputMiniBatchSize</a></strong>()</code>
<div class="block">Get current/last input mini-batch size, as set by setInputMiniBatchSize(int)</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>INDArray</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getLabels()">getLabels</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getLayer(int)">getLayer</a></strong>(int&nbsp;i)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getLayer(java.lang.String)">getLayer</a></strong>(java.lang.String&nbsp;name)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>java.util.List&lt;java.lang.String&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getLayerNames()">getLayerNames</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>[]</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getLayers()">getLayers</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/conf/MultiLayerConfiguration.html" title="class in org.deeplearning4j.nn.conf">MultiLayerConfiguration</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getLayerWiseConfigurations()">getLayerWiseConfigurations</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>java.util.Collection&lt;<a href="../../../../org/deeplearning4j/optimize/api/IterationListener.html" title="interface in org.deeplearning4j.optimize.api">IterationListener</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getListeners()">getListeners</a></strong>()</code>
<div class="block">Get the iteration listeners for this layer.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>INDArray</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getMask()">getMask</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getnLayers()">getnLayers</a></strong>()</code>
<div class="block">Get the number of layers in the network</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/optimize/api/ConvexOptimizer.html" title="interface in org.deeplearning4j.optimize.api">ConvexOptimizer</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getOptimizer()">getOptimizer</a></strong>()</code>
<div class="block">Returns this models optimizer</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getOutputLayer()">getOutputLayer</a></strong>()</code>
<div class="block">Get the output layer</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>INDArray</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getParam(java.lang.String)">getParam</a></strong>(java.lang.String&nbsp;param)</code>
<div class="block">Get the parameter</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/api/Updater.html" title="interface in org.deeplearning4j.nn.api">Updater</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getUpdater()">getUpdater</a></strong>()</code>
<div class="block">Get the updater for this MultiLayerNetwork</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#gradient()">gradient</a></strong>()</code>
<div class="block">Calculate a gradient</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>,java.lang.Double&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#gradientAndScore()">gradientAndScore</a></strong>()</code>
<div class="block">Get the gradient and score</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#init()">init</a></strong>()</code>
<div class="block">Initialize</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#initialize(DataSet)">initialize</a></strong>(DataSet&nbsp;data)</code>
<div class="block">Sets the input and labels from this dataset</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#initializeLayers(INDArray)">initializeLayers</a></strong>(INDArray&nbsp;input)</code>
<div class="block">Base class for initializing the neuralNets based on the input.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#initParams()">initParams</a></strong>()</code>
<div class="block">Initialize the parameters</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>INDArray</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#input()">input</a></strong>()</code>
<div class="block">The input/feature matrix for the model</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#intializeConfigurations()">intializeConfigurations</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#iterate(INDArray)">iterate</a></strong>(INDArray&nbsp;input)</code>
<div class="block">Run one iteration</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>INDArray</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#labelProbabilities(INDArray)">labelProbabilities</a></strong>(INDArray&nbsp;examples)</code>
<div class="block">Returns the probabilities for each label
 for each example row wise</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#merge(org.deeplearning4j.nn.api.Layer,%20int)">merge</a></strong>(<a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>&nbsp;layer,
     int&nbsp;batchSize)</code>
<div class="block">Averages the given logistic regression
 from a mini batch in to this one</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#merge(org.deeplearning4j.nn.multilayer.MultiLayerNetwork,%20int)">merge</a></strong>(<a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html" title="class in org.deeplearning4j.nn.multilayer">MultiLayerNetwork</a>&nbsp;network,
     int&nbsp;batchSize)</code>
<div class="block">Merges this network with the other one.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#numLabels()">numLabels</a></strong>()</code>
<div class="block">Returns the number of possible labels</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#numParams()">numParams</a></strong>()</code>
<div class="block">Returns a 1 x m vector where the vector is composed of
 a flattened vector of all of the weights for the
 various neuralNets and output layer</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#numParams(boolean)">numParams</a></strong>(boolean&nbsp;backwards)</code>
<div class="block">the number of parameters for the model</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>INDArray</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#output(INDArray)">output</a></strong>(INDArray&nbsp;input)</code>
<div class="block">Label the probabilities of the input</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>INDArray</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#output(INDArray,%20boolean)">output</a></strong>(INDArray&nbsp;input,
      boolean&nbsp;train)</code>
<div class="block">Label the probabilities of the input</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>INDArray</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#output(INDArray,%20boolean,%20INDArray,%20INDArray)">output</a></strong>(INDArray&nbsp;input,
      boolean&nbsp;train,
      INDArray&nbsp;featuresMask,
      INDArray&nbsp;labelsMask)</code>
<div class="block">Calculate the output of the network, with masking arrays.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>INDArray</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#output(INDArray,%20org.deeplearning4j.nn.api.Layer.TrainingMode)">output</a></strong>(INDArray&nbsp;input,
      <a href="../../../../org/deeplearning4j/nn/api/Layer.TrainingMode.html" title="enum in org.deeplearning4j.nn.api">Layer.TrainingMode</a>&nbsp;train)</code>
<div class="block">Label the probabilities of the input</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>INDArray</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#pack()">pack</a></strong>()</code>
<div class="block">Packs a set of matrices in to one vector,
 where the matrices in this case are the w,hbias at each layer
 and the output layer w,bias</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>INDArray</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#pack(java.util.List)">pack</a></strong>(java.util.List&lt;<a href="../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;INDArray,INDArray&gt;&gt;&nbsp;layers)</code>
<div class="block">Packs a set of matrices in to one vector</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>INDArray</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#params()">params</a></strong>()</code>
<div class="block">Returns a 1 x m vector where the vector is composed of
 a flattened vector of all of the weights for the
 various neuralNets(w,hbias NOT VBIAS) and output layer</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>INDArray</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#params(boolean)">params</a></strong>(boolean&nbsp;backwardOnly)</code>
<div class="block">Returns a 1 x m vector where the vector is composed of
 a flattened vector of all of the weights for the
 various neuralNets(w,hbias NOT VBIAS) and output layer</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>java.util.Map&lt;java.lang.String,INDArray&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#paramTable()">paramTable</a></strong>()</code>
<div class="block">The param table</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>int[]</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#predict(INDArray)">predict</a></strong>(INDArray&nbsp;d)</code>
<div class="block">Returns the predictions for each example in the dataset</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>INDArray</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#preOutput(INDArray)">preOutput</a></strong>(INDArray&nbsp;x)</code>
<div class="block">Raw activations</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>INDArray</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#preOutput(INDArray,%20boolean)">preOutput</a></strong>(INDArray&nbsp;x,
         boolean&nbsp;training)</code>
<div class="block">Raw activations</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>INDArray</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#preOutput(INDArray,%20org.deeplearning4j.nn.api.Layer.TrainingMode)">preOutput</a></strong>(INDArray&nbsp;x,
         <a href="../../../../org/deeplearning4j/nn/api/Layer.TrainingMode.html" title="enum in org.deeplearning4j.nn.api">Layer.TrainingMode</a>&nbsp;training)</code>
<div class="block">Raw activations</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#pretrain(DataSetIterator)">pretrain</a></strong>(DataSetIterator&nbsp;iter)</code>
<div class="block">This unsupervised learning method runs
 contrastive divergence on each RBM layer in the network.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#pretrain(INDArray)">pretrain</a></strong>(INDArray&nbsp;input)</code>
<div class="block">This unsupervised learning method runs
 contrastive divergence on each RBM layer in the network.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#printConfiguration()">printConfiguration</a></strong>()</code>
<div class="block">Prints the configuration</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>INDArray</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#reconstruct(INDArray,%20int)">reconstruct</a></strong>(INDArray&nbsp;x,
           int&nbsp;layerNum)</code>
<div class="block">Reconstructs the input.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#reDistributeParams(boolean)">reDistributeParams</a></strong>(boolean&nbsp;backwardOnly)</code>
<div class="block">Redistribute parameters handles
 having parameters as a view</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#reductionRatio(INDArray,%20double,%20double,%20INDArray)">reductionRatio</a></strong>(INDArray&nbsp;p,
              double&nbsp;currScore,
              double&nbsp;score,
              INDArray&nbsp;gradient)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>java.util.List&lt;INDArray&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#rnnActivateUsingStoredState(INDArray,%20boolean,%20boolean)">rnnActivateUsingStoredState</a></strong>(INDArray&nbsp;input,
                           boolean&nbsp;training,
                           boolean&nbsp;storeLastForTBPTT)</code>
<div class="block">Similar to rnnTimeStep and feedForward() methods.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#rnnClearPreviousState()">rnnClearPreviousState</a></strong>()</code>
<div class="block">Clear the previous state of the RNN layers (if any).</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>java.util.Map&lt;java.lang.String,INDArray&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#rnnGetPreviousState(int)">rnnGetPreviousState</a></strong>(int&nbsp;layer)</code>
<div class="block">Get the state of the RNN layer, as used in rnnTimeStep().</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#rnnSetPreviousState(int,%20java.util.Map)">rnnSetPreviousState</a></strong>(int&nbsp;layer,
                   java.util.Map&lt;java.lang.String,INDArray&gt;&nbsp;state)</code>
<div class="block">Set the state of the RNN layer.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>INDArray</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#rnnTimeStep(INDArray)">rnnTimeStep</a></strong>(INDArray&nbsp;input)</code>
<div class="block">If this MultiLayerNetwork contains one or more RNN layers: conduct forward pass (prediction)
 but using previous stored state for any RNN layers.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#score()">score</a></strong>()</code>
<div class="block">Score of the model (relative to the objective function)</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#score(DataSet)">score</a></strong>(DataSet&nbsp;data)</code>
<div class="block">Sets the input and labels and returns a score for the prediction with respect to the true labels<br>
 This is equivalent to <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#score(DataSet,%20boolean)"><code>score(DataSet, boolean)</code></a> with training==true.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#score(DataSet,%20boolean)">score</a></strong>(DataSet&nbsp;data,
     boolean&nbsp;training)</code>
<div class="block">Calculate the score (loss function) of the prediction with respect to the true labels<br></div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#score(INDArray)">score</a></strong>(INDArray&nbsp;param)</code>
<div class="block"><strong>Deprecated.</strong>&nbsp;</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setConf(org.deeplearning4j.nn.conf.NeuralNetConfiguration)">setConf</a></strong>(<a href="../../../../org/deeplearning4j/nn/conf/NeuralNetConfiguration.html" title="class in org.deeplearning4j.nn.conf">NeuralNetConfiguration</a>&nbsp;conf)</code>
<div class="block">Setter for the configuration</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setIndex(int)">setIndex</a></strong>(int&nbsp;index)</code>
<div class="block">Set the layer index.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setInput(INDArray)">setInput</a></strong>(INDArray&nbsp;input)</code>
<div class="block">Note that if input isn't null
 and the neuralNets are null, this is a way
 of initializing the neural network</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setInputMiniBatchSize(int)">setInputMiniBatchSize</a></strong>(int&nbsp;size)</code>
<div class="block">Set current/last input mini-batch size.<br>
 Used for score and gradient calculations.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setLabels(INDArray)">setLabels</a></strong>(INDArray&nbsp;labels)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setLayerMaskArrays(INDArray,%20INDArray)">setLayerMaskArrays</a></strong>(INDArray&nbsp;featuresMaskArray,
                  INDArray&nbsp;labelsMaskArray)</code>
<div class="block">Set the mask arrays for features and labels.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setLayers(org.deeplearning4j.nn.api.Layer[])">setLayers</a></strong>(<a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>[]&nbsp;layers)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setLayerWiseConfigurations(org.deeplearning4j.nn.conf.MultiLayerConfiguration)">setLayerWiseConfigurations</a></strong>(<a href="../../../../org/deeplearning4j/nn/conf/MultiLayerConfiguration.html" title="class in org.deeplearning4j.nn.conf">MultiLayerConfiguration</a>&nbsp;layerWiseConfigurations)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setListeners(java.util.Collection)">setListeners</a></strong>(java.util.Collection&lt;<a href="../../../../org/deeplearning4j/optimize/api/IterationListener.html" title="interface in org.deeplearning4j.optimize.api">IterationListener</a>&gt;&nbsp;listeners)</code>
<div class="block">Set the iteration listeners for this layer.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setListeners(org.deeplearning4j.optimize.api.IterationListener...)">setListeners</a></strong>(<a href="../../../../org/deeplearning4j/optimize/api/IterationListener.html" title="interface in org.deeplearning4j.optimize.api">IterationListener</a>...&nbsp;listeners)</code>
<div class="block">Set the iteration listeners for this layer.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setMask(INDArray)">setMask</a></strong>(INDArray&nbsp;mask)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setMaskArray(INDArray)">setMaskArray</a></strong>(INDArray&nbsp;maskArray)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setParam(java.lang.String,%20INDArray)">setParam</a></strong>(java.lang.String&nbsp;key,
        INDArray&nbsp;val)</code>
<div class="block">Set the parameter with a new ndarray</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setParameters(INDArray)">setParameters</a></strong>(INDArray&nbsp;params)</code>
<div class="block">Sets parameters for the model.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setParams(INDArray)">setParams</a></strong>(INDArray&nbsp;params)</code>
<div class="block">Set the parameters for this model.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setParamTable(java.util.Map)">setParamTable</a></strong>(java.util.Map&lt;java.lang.String,INDArray&gt;&nbsp;paramTable)</code>
<div class="block">Setter for the param table</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setUpdater(org.deeplearning4j.nn.api.Updater)">setUpdater</a></strong>(<a href="../../../../org/deeplearning4j/nn/api/Updater.html" title="interface in org.deeplearning4j.nn.api">Updater</a>&nbsp;updater)</code>
<div class="block">Set the updater for the MultiLayerNetwork</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#transpose()">transpose</a></strong>()</code>
<div class="block">Return a transposed copy of the weights/bias
 (this means reverse the number of inputs and outputs on the weights)</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#truncatedBPTTGradient()">truncatedBPTTGradient</a></strong>()</code>
<div class="block">Equivalent to backprop(), but calculates gradient for truncated BPTT instead.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/api/Layer.Type.html" title="enum in org.deeplearning4j.nn.api">Layer.Type</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#type()">type</a></strong>()</code>
<div class="block">Returns the layer type</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>java.util.List&lt;<a href="../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;INDArray,INDArray&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#unPack(INDArray)">unPack</a></strong>(INDArray&nbsp;param)</code>
<div class="block">Unpacks a parameter matrix in to a
 transform of pairs(w,hbias)
 triples with layer wise</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#update(org.deeplearning4j.nn.gradient.Gradient)">update</a></strong>(<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>&nbsp;gradient)</code>
<div class="block">Update layer weights and biases with gradient change</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#update(INDArray,%20java.lang.String)">update</a></strong>(INDArray&nbsp;gradient,
      java.lang.String&nbsp;paramType)</code>
<div class="block">Perform one update  applying the gradient</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#update(org.deeplearning4j.nn.multilayer.MultiLayerNetwork)">update</a></strong>(<a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html" title="class in org.deeplearning4j.nn.multilayer">MultiLayerNetwork</a>&nbsp;network)</code>
<div class="block">Assigns the parameters of this model to the ones specified by this
 network.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#updateRnnStateWithTBPTTState()">updateRnnStateWithTBPTTState</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#validateInput()">validateInput</a></strong>()</code>
<div class="block">Validate the input</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>INDArray</code></td>
<td class="colLast"><code><strong><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#zFromPrevLayer(int,%20INDArray,%20boolean)">zFromPrevLayer</a></strong>(int&nbsp;curr,
              INDArray&nbsp;input,
              boolean&nbsp;training)</code>
<div class="block">Compute input linear transformation (z) from previous layer
 Apply pre processing transformation where necessary</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_java.lang.Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;java.lang.Object</h3>
<code>equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ============ FIELD DETAIL =========== -->
<ul class="blockList">
<li class="blockList"><a name="field_detail">
<!--   -->
</a>
<h3>Field Detail</h3>
<a name="layers">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>layers</h4>
<pre>protected&nbsp;<a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>[] layers</pre>
</li>
</ul>
<a name="layerMap">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>layerMap</h4>
<pre>protected&nbsp;java.util.LinkedHashMap&lt;java.lang.String,<a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>&gt; layerMap</pre>
</li>
</ul>
<a name="input">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>input</h4>
<pre>protected&nbsp;INDArray input</pre>
</li>
</ul>
<a name="labels">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>labels</h4>
<pre>protected&nbsp;INDArray labels</pre>
</li>
</ul>
<a name="initCalled">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>initCalled</h4>
<pre>protected&nbsp;boolean initCalled</pre>
</li>
</ul>
<a name="defaultConfiguration">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>defaultConfiguration</h4>
<pre>protected&nbsp;<a href="../../../../org/deeplearning4j/nn/conf/NeuralNetConfiguration.html" title="class in org.deeplearning4j.nn.conf">NeuralNetConfiguration</a> defaultConfiguration</pre>
</li>
</ul>
<a name="layerWiseConfigurations">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>layerWiseConfigurations</h4>
<pre>protected&nbsp;<a href="../../../../org/deeplearning4j/nn/conf/MultiLayerConfiguration.html" title="class in org.deeplearning4j.nn.conf">MultiLayerConfiguration</a> layerWiseConfigurations</pre>
</li>
</ul>
<a name="gradient">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>gradient</h4>
<pre>protected&nbsp;<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a> gradient</pre>
</li>
</ul>
<a name="score">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>score</h4>
<pre>protected&nbsp;double score</pre>
</li>
</ul>
<a name="mask">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>mask</h4>
<pre>protected&nbsp;INDArray mask</pre>
</li>
</ul>
<a name="layerIndex">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>layerIndex</h4>
<pre>protected&nbsp;int layerIndex</pre>
</li>
</ul>
<a name="solver">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>solver</h4>
<pre>protected transient&nbsp;<a href="../../../../org/deeplearning4j/optimize/Solver.html" title="class in org.deeplearning4j.optimize">Solver</a> solver</pre>
</li>
</ul>
</li>
</ul>
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a name="MultiLayerNetwork(org.deeplearning4j.nn.conf.MultiLayerConfiguration)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>MultiLayerNetwork</h4>
<pre>public&nbsp;MultiLayerNetwork(<a href="../../../../org/deeplearning4j/nn/conf/MultiLayerConfiguration.html" title="class in org.deeplearning4j.nn.conf">MultiLayerConfiguration</a>&nbsp;conf)</pre>
</li>
</ul>
<a name="MultiLayerNetwork(java.lang.String, INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>MultiLayerNetwork</h4>
<pre>public&nbsp;MultiLayerNetwork(java.lang.String&nbsp;conf,
                 INDArray&nbsp;params)</pre>
<div class="block">Initialize the network based on the configuration</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>conf</code> - the configuration json</dd><dd><code>params</code> - the parameters</dd></dl>
</li>
</ul>
<a name="MultiLayerNetwork(org.deeplearning4j.nn.conf.MultiLayerConfiguration, INDArray)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>MultiLayerNetwork</h4>
<pre>public&nbsp;MultiLayerNetwork(<a href="../../../../org/deeplearning4j/nn/conf/MultiLayerConfiguration.html" title="class in org.deeplearning4j.nn.conf">MultiLayerConfiguration</a>&nbsp;conf,
                 INDArray&nbsp;params)</pre>
<div class="block">Initialize the network based on the configuraiton</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>conf</code> - the configuration</dd><dd><code>params</code> - the parameters</dd></dl>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method_detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="intializeConfigurations()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>intializeConfigurations</h4>
<pre>protected&nbsp;void&nbsp;intializeConfigurations()</pre>
</li>
</ul>
<a name="pretrain(DataSetIterator)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>pretrain</h4>
<pre>public&nbsp;void&nbsp;pretrain(DataSetIterator&nbsp;iter)</pre>
<div class="block">This unsupervised learning method runs
 contrastive divergence on each RBM layer in the network.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>iter</code> - the input to iterate on
             The typical tip is that the higher k is the closer to the model
             you will be approximating due to more sampling. K = 1
             usually gives very good results and is the default in quite a few situations.</dd></dl>
</li>
</ul>
<a name="pretrain(INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>pretrain</h4>
<pre>public&nbsp;void&nbsp;pretrain(INDArray&nbsp;input)</pre>
<div class="block">This unsupervised learning method runs
 contrastive divergence on each RBM layer in the network.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>input</code> - the input to iterate on
              The typical tip is that the higher k is the closer to the model
              you will be approximating due to more sampling. K = 1
              usually gives very good results and is the default in quite a few situations.</dd></dl>
</li>
</ul>
<a name="batchSize()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>batchSize</h4>
<pre>public&nbsp;int&nbsp;batchSize()</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#batchSize()">Model</a></code></strong></div>
<div class="block">The current inputs batch size</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#batchSize()">batchSize</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="strong">Returns:</span></dt><dd>the current inputs batch size</dd></dl>
</li>
</ul>
<a name="conf()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>conf</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/conf/NeuralNetConfiguration.html" title="class in org.deeplearning4j.nn.conf">NeuralNetConfiguration</a>&nbsp;conf()</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#conf()">Model</a></code></strong></div>
<div class="block">The configuration for the neural network</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#conf()">conf</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="strong">Returns:</span></dt><dd>the configuration for the neural network</dd></dl>
</li>
</ul>
<a name="setConf(org.deeplearning4j.nn.conf.NeuralNetConfiguration)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setConf</h4>
<pre>public&nbsp;void&nbsp;setConf(<a href="../../../../org/deeplearning4j/nn/conf/NeuralNetConfiguration.html" title="class in org.deeplearning4j.nn.conf">NeuralNetConfiguration</a>&nbsp;conf)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#setConf(org.deeplearning4j.nn.conf.NeuralNetConfiguration)">Model</a></code></strong></div>
<div class="block">Setter for the configuration</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#setConf(org.deeplearning4j.nn.conf.NeuralNetConfiguration)">setConf</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="input()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>input</h4>
<pre>public&nbsp;INDArray&nbsp;input()</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#input()">Model</a></code></strong></div>
<div class="block">The input/feature matrix for the model</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#input()">input</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="strong">Returns:</span></dt><dd>the input/feature matrix for the model</dd></dl>
</li>
</ul>
<a name="validateInput()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>validateInput</h4>
<pre>public&nbsp;void&nbsp;validateInput()</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#validateInput()">Model</a></code></strong></div>
<div class="block">Validate the input</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#validateInput()">validateInput</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="getOptimizer()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getOptimizer</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/optimize/api/ConvexOptimizer.html" title="interface in org.deeplearning4j.optimize.api">ConvexOptimizer</a>&nbsp;getOptimizer()</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#getOptimizer()">Model</a></code></strong></div>
<div class="block">Returns this models optimizer</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#getOptimizer()">getOptimizer</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="strong">Returns:</span></dt><dd>this models optimizer</dd></dl>
</li>
</ul>
<a name="getParam(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getParam</h4>
<pre>public&nbsp;INDArray&nbsp;getParam(java.lang.String&nbsp;param)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#getParam(java.lang.String)">Model</a></code></strong></div>
<div class="block">Get the parameter</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#getParam(java.lang.String)">getParam</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>param</code> - the key of the parameter</dd>
<dt><span class="strong">Returns:</span></dt><dd>the parameter vector/matrix with that particular key</dd></dl>
</li>
</ul>
<a name="initParams()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>initParams</h4>
<pre>public&nbsp;void&nbsp;initParams()</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#initParams()">Model</a></code></strong></div>
<div class="block">Initialize the parameters</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#initParams()">initParams</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="paramTable()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>paramTable</h4>
<pre>public&nbsp;java.util.Map&lt;java.lang.String,INDArray&gt;&nbsp;paramTable()</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#paramTable()">Model</a></code></strong></div>
<div class="block">The param table</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#paramTable()">paramTable</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="strong">Returns:</span></dt><dd></dd></dl>
</li>
</ul>
<a name="setParamTable(java.util.Map)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setParamTable</h4>
<pre>public&nbsp;void&nbsp;setParamTable(java.util.Map&lt;java.lang.String,INDArray&gt;&nbsp;paramTable)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#setParamTable(java.util.Map)">Model</a></code></strong></div>
<div class="block">Setter for the param table</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#setParamTable(java.util.Map)">setParamTable</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="setParam(java.lang.String, INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setParam</h4>
<pre>public&nbsp;void&nbsp;setParam(java.lang.String&nbsp;key,
            INDArray&nbsp;val)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#setParam(java.lang.String,%20INDArray)">Model</a></code></strong></div>
<div class="block">Set the parameter with a new ndarray</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#setParam(java.lang.String,%20INDArray)">setParam</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>key</code> - the key to se t</dd><dd><code>val</code> - the new ndarray</dd></dl>
</li>
</ul>
<a name="getLayerWiseConfigurations()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLayerWiseConfigurations</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/conf/MultiLayerConfiguration.html" title="class in org.deeplearning4j.nn.conf">MultiLayerConfiguration</a>&nbsp;getLayerWiseConfigurations()</pre>
</li>
</ul>
<a name="setLayerWiseConfigurations(org.deeplearning4j.nn.conf.MultiLayerConfiguration)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setLayerWiseConfigurations</h4>
<pre>public&nbsp;void&nbsp;setLayerWiseConfigurations(<a href="../../../../org/deeplearning4j/nn/conf/MultiLayerConfiguration.html" title="class in org.deeplearning4j.nn.conf">MultiLayerConfiguration</a>&nbsp;layerWiseConfigurations)</pre>
</li>
</ul>
<a name="initializeLayers(INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>initializeLayers</h4>
<pre>public&nbsp;void&nbsp;initializeLayers(INDArray&nbsp;input)</pre>
<div class="block">Base class for initializing the neuralNets based on the input.
 This is meant for capturing numbers such as input columns or other things.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>input</code> - the input matrix for training</dd></dl>
</li>
</ul>
<a name="init()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>init</h4>
<pre>public&nbsp;void&nbsp;init()</pre>
<div class="block">Initialize</div>
</li>
</ul>
<a name="activate()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>activate</h4>
<pre>public&nbsp;INDArray&nbsp;activate()</pre>
<div class="block">Triggers the activation of the last hidden layer ie: not logistic regression</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#activate()">activate</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="strong">Returns:</span></dt><dd>the activation of the last hidden layer given the last input to the network</dd></dl>
</li>
</ul>
<a name="activate(int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>activate</h4>
<pre>public&nbsp;INDArray&nbsp;activate(int&nbsp;layer)</pre>
<div class="block">Triggers the activation for a given layer</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#activate(INDArray)">activate</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>layer</code> - the layer to activate on</dd>
<dt><span class="strong">Returns:</span></dt><dd>the activation for a given layer</dd></dl>
</li>
</ul>
<a name="activate(INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>activate</h4>
<pre>public&nbsp;INDArray&nbsp;activate(INDArray&nbsp;input)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#activate(org.deeplearning4j.nn.api.Layer.TrainingMode)">Layer</a></code></strong></div>
<div class="block">Trigger an activation with the last specified input</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#activate(org.deeplearning4j.nn.api.Layer.TrainingMode)">activate</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>input</code> - training or test mode</dd>
<dt><span class="strong">Returns:</span></dt><dd>the activation of the last specified input</dd></dl>
</li>
</ul>
<a name="activate(int, INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>activate</h4>
<pre>public&nbsp;INDArray&nbsp;activate(int&nbsp;layer,
                INDArray&nbsp;input)</pre>
<div class="block">Triggers the activation of the given layer</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#activate(INDArray,%20org.deeplearning4j.nn.api.Layer.TrainingMode)">activate</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>layer</code> - the layer to trigger on</dd><dd><code>input</code> - the input to the hidden layer</dd>
<dt><span class="strong">Returns:</span></dt><dd>the activation of the layer based on the input</dd></dl>
</li>
</ul>
<a name="activationMean()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>activationMean</h4>
<pre>public&nbsp;INDArray&nbsp;activationMean()</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#activationMean()">Layer</a></code></strong></div>
<div class="block">Calculate the mean representation
 for the activation for this layer</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#activationMean()">activationMean</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="strong">Returns:</span></dt><dd>the activation mean for this layer</dd></dl>
</li>
</ul>
<a name="reDistributeParams(boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>reDistributeParams</h4>
<pre>public&nbsp;void&nbsp;reDistributeParams(boolean&nbsp;backwardOnly)</pre>
<div class="block">Redistribute parameters handles
 having parameters as a view</div>
</li>
</ul>
<a name="initialize(DataSet)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>initialize</h4>
<pre>public&nbsp;void&nbsp;initialize(DataSet&nbsp;data)</pre>
<div class="block">Sets the input and labels from this dataset</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>data</code> - the dataset to initialize with</dd></dl>
</li>
</ul>
<a name="zFromPrevLayer(int, INDArray, boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>zFromPrevLayer</h4>
<pre>public&nbsp;INDArray&nbsp;zFromPrevLayer(int&nbsp;curr,
                      INDArray&nbsp;input,
                      boolean&nbsp;training)</pre>
<div class="block">Compute input linear transformation (z) from previous layer
 Apply pre processing transformation where necessary</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>curr</code> - the current layer</dd><dd><code>input</code> - the input</dd><dd><code>training</code> - training or test mode</dd>
<dt><span class="strong">Returns:</span></dt><dd>the activation from the previous layer</dd></dl>
</li>
</ul>
<a name="activationFromPrevLayer(int, INDArray, boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>activationFromPrevLayer</h4>
<pre>public&nbsp;INDArray&nbsp;activationFromPrevLayer(int&nbsp;curr,
                               INDArray&nbsp;input,
                               boolean&nbsp;training)</pre>
<div class="block">Calculate activation from previous layer including pre processing where necessary</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>curr</code> - the current layer</dd><dd><code>input</code> - the input</dd>
<dt><span class="strong">Returns:</span></dt><dd>the activation from the previous layer</dd></dl>
</li>
</ul>
<a name="activateSelectedLayers(int, int, INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>activateSelectedLayers</h4>
<pre>public&nbsp;INDArray&nbsp;activateSelectedLayers(int&nbsp;from,
                              int&nbsp;to,
                              INDArray&nbsp;input)</pre>
<div class="block">Calculate activation for few layers at once. Suitable for autoencoder partial activation.

 In example: in 10-layer deep autoencoder, layers 0 - 4 inclusive are used for encoding part, and layers 5-9 inclusive are used for decoding part.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>from</code> - first layer to be activated, inclusive</dd><dd><code>to</code> - last layer to be activated, inclusive</dd>
<dt><span class="strong">Returns:</span></dt><dd>the activation from the last layer</dd></dl>
</li>
</ul>
<a name="computeZ(boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>computeZ</h4>
<pre>public&nbsp;java.util.List&lt;INDArray&gt;&nbsp;computeZ(boolean&nbsp;training)</pre>
<div class="block">* Compute input linear transformation (z) of the output layer</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>the list of activations for each layer</dd></dl>
</li>
</ul>
<a name="computeZ(INDArray, boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>computeZ</h4>
<pre>public&nbsp;java.util.List&lt;INDArray&gt;&nbsp;computeZ(INDArray&nbsp;input,
                                boolean&nbsp;training)</pre>
<div class="block">Compute activations from input to output of the output layer</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>the list of activations for each layer</dd></dl>
</li>
</ul>
<a name="feedForward(INDArray, boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>feedForward</h4>
<pre>public&nbsp;java.util.List&lt;INDArray&gt;&nbsp;feedForward(INDArray&nbsp;input,
                                   boolean&nbsp;train)</pre>
<div class="block">Compute activations from input to output of the output layer</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>the list of activations for each layer</dd></dl>
</li>
</ul>
<a name="feedForward(boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>feedForward</h4>
<pre>public&nbsp;java.util.List&lt;INDArray&gt;&nbsp;feedForward(boolean&nbsp;train)</pre>
<div class="block">Compute activations from input to output of the output layer</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>the list of activations for each layer</dd></dl>
</li>
</ul>
<a name="feedForwardToLayer(int, INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>feedForwardToLayer</h4>
<pre>public&nbsp;java.util.List&lt;INDArray&gt;&nbsp;feedForwardToLayer(int&nbsp;layerNum,
                                          INDArray&nbsp;input)</pre>
<div class="block">Compute the activations from the input to the specified layer.<br>
 To compute activations for all layers, use feedForward(...) methods<br>
 Note: output list includes the original input. So list.get(0) is always the original input, and
 list.get(i+1) is the activations of the ith layer.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>layerNum</code> - Index of the last layer to calculate activations for. Layers are zero-indexed.
                 feedForwardToLayer(i,input) will return the activations for layers 0..i (inclusive)</dd><dd><code>input</code> - Input to the network</dd>
<dt><span class="strong">Returns:</span></dt><dd>list of activations.</dd></dl>
</li>
</ul>
<a name="feedForwardToLayer(int, INDArray, boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>feedForwardToLayer</h4>
<pre>public&nbsp;java.util.List&lt;INDArray&gt;&nbsp;feedForwardToLayer(int&nbsp;layerNum,
                                          INDArray&nbsp;input,
                                          boolean&nbsp;train)</pre>
<div class="block">Compute the activations from the input to the specified layer.<br>
 To compute activations for all layers, use feedForward(...) methods<br>
 Note: output list includes the original input. So list.get(0) is always the original input, and
 list.get(i+1) is the activations of the ith layer.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>layerNum</code> - Index of the last layer to calculate activations for. Layers are zero-indexed.
                 feedForwardToLayer(i,input) will return the activations for layers 0..i (inclusive)</dd><dd><code>input</code> - Input to the network</dd><dd><code>train</code> - true for training, false for test (i.e., false if using network after training)</dd>
<dt><span class="strong">Returns:</span></dt><dd>list of activations.</dd></dl>
</li>
</ul>
<a name="feedForwardToLayer(int, boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>feedForwardToLayer</h4>
<pre>public&nbsp;java.util.List&lt;INDArray&gt;&nbsp;feedForwardToLayer(int&nbsp;layerNum,
                                          boolean&nbsp;train)</pre>
<div class="block">Compute the activations from the input to the specified layer, using the currently set input for the network.<br>
 To compute activations for all layers, use feedForward(...) methods<br>
 Note: output list includes the original input. So list.get(0) is always the original input, and
 list.get(i+1) is the activations of the ith layer.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>layerNum</code> - Index of the last layer to calculate activations for. Layers are zero-indexed.
                 feedForwardToLayer(i,input) will return the activations for layers 0..i (inclusive)</dd><dd><code>train</code> - true for training, false for test (i.e., false if using network after training)</dd>
<dt><span class="strong">Returns:</span></dt><dd>list of activations.</dd></dl>
</li>
</ul>
<a name="feedForward()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>feedForward</h4>
<pre>public&nbsp;java.util.List&lt;INDArray&gt;&nbsp;feedForward()</pre>
<div class="block">Compute activations from input to output of the output layer</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>the list of activations for each layer</dd></dl>
</li>
</ul>
<a name="feedForwardActivationsAndDerivatives(boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>feedForwardActivationsAndDerivatives</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;java.util.List&lt;INDArray&gt;,java.util.List&lt;INDArray&gt;&gt;&nbsp;feedForwardActivationsAndDerivatives(boolean&nbsp;training)</pre>
<div class="block">Compute input linear transformation (z)
 Compute activations (applies activation transformation to z)</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>a pair of activations and corresponding derivatives</dd></dl>
</li>
</ul>
<a name="feedForward(INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>feedForward</h4>
<pre>public&nbsp;java.util.List&lt;INDArray&gt;&nbsp;feedForward(INDArray&nbsp;input)</pre>
<div class="block">Compute activations from input to output of the output layer</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>the list of activations for each layer</dd></dl>
</li>
</ul>
<a name="feedForward(INDArray, INDArray, INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>feedForward</h4>
<pre>public&nbsp;java.util.List&lt;INDArray&gt;&nbsp;feedForward(INDArray&nbsp;input,
                                   INDArray&nbsp;featuresMask,
                                   INDArray&nbsp;labelsMask)</pre>
<div class="block">Compute the activations from the input to the output layer, given mask arrays (that may be null)
 The masking arrays are used in situations such an one-to-many and many-to-one rucerrent neural network (RNN)
 designs, as well as for supporting time series of varying lengths within the same minibatch for RNNs.</div>
</li>
</ul>
<a name="gradient()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>gradient</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>&nbsp;gradient()</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#gradient()">Model</a></code></strong></div>
<div class="block">Calculate a gradient</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#gradient()">gradient</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="strong">Returns:</span></dt><dd>the gradient for this model</dd></dl>
</li>
</ul>
<a name="gradientAndScore()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>gradientAndScore</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>,java.lang.Double&gt;&nbsp;gradientAndScore()</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#gradientAndScore()">Model</a></code></strong></div>
<div class="block">Get the gradient and score</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#gradientAndScore()">gradientAndScore</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="strong">Returns:</span></dt><dd>the gradient and score</dd></dl>
</li>
</ul>
<a name="computeDeltasR(INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>computeDeltasR</h4>
<pre>protected&nbsp;java.util.List&lt;INDArray&gt;&nbsp;computeDeltasR(INDArray&nbsp;v)</pre>
</li>
</ul>
<a name="dampingUpdate(double, double, double)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>dampingUpdate</h4>
<pre>public&nbsp;void&nbsp;dampingUpdate(double&nbsp;rho,
                 double&nbsp;boost,
                 double&nbsp;decrease)</pre>
</li>
</ul>
<a name="reductionRatio(INDArray, double, double, INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>reductionRatio</h4>
<pre>public&nbsp;double&nbsp;reductionRatio(INDArray&nbsp;p,
                    double&nbsp;currScore,
                    double&nbsp;score,
                    INDArray&nbsp;gradient)</pre>
</li>
</ul>
<a name="computeDeltas2()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>computeDeltas2</h4>
<pre>protected&nbsp;java.util.List&lt;<a href="../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;INDArray,INDArray&gt;&gt;&nbsp;computeDeltas2()</pre>
</li>
</ul>
<a name="getBackPropRGradient(INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getBackPropRGradient</h4>
<pre>public&nbsp;INDArray&nbsp;getBackPropRGradient(INDArray&nbsp;v)</pre>
<div class="block">Gets the back prop gradient with the r operator (gauss vector)
 This is also called computeGV</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>v</code> - the v in gaussian newton vector g * v</dd>
<dt><span class="strong">Returns:</span></dt><dd>the back prop with r gradient</dd></dl>
</li>
</ul>
<a name="getBackPropGradient2()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getBackPropGradient2</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;INDArray,INDArray&gt;&nbsp;getBackPropGradient2()</pre>
<div class="block">Gets the back prop gradient with the r operator (gauss vector)
 and the associated precon matrix
 This is also called computeGV</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>the back prop with r gradient</dd></dl>
</li>
</ul>
<a name="clone()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>clone</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html" title="class in org.deeplearning4j.nn.multilayer">MultiLayerNetwork</a>&nbsp;clone()</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#clone()">Layer</a></code></strong></div>
<div class="block">Clone the layer</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#clone()">clone</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><strong>Overrides:</strong></dt>
<dd><code>clone</code>&nbsp;in class&nbsp;<code>java.lang.Object</code></dd>
<dt><span class="strong">Returns:</span></dt><dd></dd></dl>
</li>
</ul>
<a name="params(boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>params</h4>
<pre>public&nbsp;INDArray&nbsp;params(boolean&nbsp;backwardOnly)</pre>
<div class="block">Returns a 1 x m vector where the vector is composed of
 a flattened vector of all of the weights for the
 various neuralNets(w,hbias NOT VBIAS) and output layer</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>the params for this neural net</dd></dl>
</li>
</ul>
<a name="params()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>params</h4>
<pre>public&nbsp;INDArray&nbsp;params()</pre>
<div class="block">Returns a 1 x m vector where the vector is composed of
 a flattened vector of all of the weights for the
 various neuralNets(w,hbias NOT VBIAS) and output layer</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#params()">params</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="strong">Returns:</span></dt><dd>the params for this neural net</dd></dl>
</li>
</ul>
<a name="setParams(INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setParams</h4>
<pre>public&nbsp;void&nbsp;setParams(INDArray&nbsp;params)</pre>
<div class="block">Set the parameters for this model.
 This expects a linear ndarray
 which then be unpacked internally
 relative to the expected ordering of the model</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#setParams(INDArray)">setParams</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>params</code> - the parameters for the model</dd></dl>
</li>
</ul>
<a name="numParams()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>numParams</h4>
<pre>public&nbsp;int&nbsp;numParams()</pre>
<div class="block">Returns a 1 x m vector where the vector is composed of
 a flattened vector of all of the weights for the
 various neuralNets and output layer</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#numParams()">numParams</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="strong">Returns:</span></dt><dd>the params for this neural net</dd></dl>
</li>
</ul>
<a name="numParams(boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>numParams</h4>
<pre>public&nbsp;int&nbsp;numParams(boolean&nbsp;backwards)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#numParams(boolean)">Model</a></code></strong></div>
<div class="block">the number of parameters for the model</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#numParams(boolean)">numParams</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="strong">Returns:</span></dt><dd>the number of parameters for the model</dd></dl>
</li>
</ul>
<a name="pack()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>pack</h4>
<pre>public&nbsp;INDArray&nbsp;pack()</pre>
<div class="block">Packs a set of matrices in to one vector,
 where the matrices in this case are the w,hbias at each layer
 and the output layer w,bias</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>a singular matrix of all of the neuralNets packed in to one matrix</dd></dl>
</li>
</ul>
<a name="pack(java.util.List)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>pack</h4>
<pre>public&nbsp;INDArray&nbsp;pack(java.util.List&lt;<a href="../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;INDArray,INDArray&gt;&gt;&nbsp;layers)</pre>
<div class="block">Packs a set of matrices in to one vector</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>layers</code> - the neuralNets to pack</dd>
<dt><span class="strong">Returns:</span></dt><dd>a singular matrix of all of the neuralNets packed in to one matrix</dd></dl>
</li>
</ul>
<a name="f1Score(org.nd4j.linalg.dataset.api.DataSet)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>f1Score</h4>
<pre>public&nbsp;double&nbsp;f1Score(org.nd4j.linalg.dataset.api.DataSet&nbsp;data)</pre>
<div class="block">Sets the input and labels and returns a score for the prediction
 wrt true labels</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html#f1Score(DataSet)">f1Score</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html" title="interface in org.deeplearning4j.nn.api">Classifier</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>data</code> - the data to score</dd>
<dt><span class="strong">Returns:</span></dt><dd>the score for the given input,label pairs</dd></dl>
</li>
</ul>
<a name="unPack(INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>unPack</h4>
<pre>public&nbsp;java.util.List&lt;<a href="../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;INDArray,INDArray&gt;&gt;&nbsp;unPack(INDArray&nbsp;param)</pre>
<div class="block">Unpacks a parameter matrix in to a
 transform of pairs(w,hbias)
 triples with layer wise</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>param</code> - the param vector</dd>
<dt><span class="strong">Returns:</span></dt><dd>a segmented list of the param vector</dd></dl>
</li>
</ul>
<a name="backPropGradient2()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>backPropGradient2</h4>
<pre>protected&nbsp;java.util.List&lt;<a href="../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;<a href="../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;INDArray,INDArray&gt;,<a href="../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;INDArray,INDArray&gt;&gt;&gt;&nbsp;backPropGradient2()</pre>
<div class="block">Do a back prop iteration.
 This involves computing the activations, tracking the last neuralNets weights
 to revert to in case of convergence, the learning rate being used to iterate
 and the current epoch</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>whether the training should converge or not</dd></dl>
</li>
</ul>
<a name="fit(DataSetIterator)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>fit</h4>
<pre>public&nbsp;void&nbsp;fit(DataSetIterator&nbsp;iter)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html#fit(DataSetIterator)">Classifier</a></code></strong></div>
<div class="block">Train the model based on the datasetiterator</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html#fit(DataSetIterator)">fit</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html" title="interface in org.deeplearning4j.nn.api">Classifier</a></code></dd>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#fit(INDArray)">fit</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>iter</code> - the iterator to train on</dd></dl>
</li>
</ul>
<a name="backprop()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>backprop</h4>
<pre>protected&nbsp;void&nbsp;backprop()</pre>
<div class="block">Calculate and set gradients for MultiLayerNetwork, based on OutputLayer and labels</div>
</li>
</ul>
<a name="calcBackpropGradients(INDArray, boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>calcBackpropGradients</h4>
<pre>protected&nbsp;<a href="../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>,INDArray&gt;&nbsp;calcBackpropGradients(INDArray&nbsp;epsilon,
                                            boolean&nbsp;withOutputLayer)</pre>
<div class="block">Calculate gradients and errors. Used in two places:
 (a) backprop (for standard multi layer network learning)
 (b) backpropGradient (layer method, for when MultiLayerNetwork is used as a layer)</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>epsilon</code> - Errors (technically errors .* activations). Not used if withOutputLayer = true</dd><dd><code>withOutputLayer</code> - if true: assume last layer is output layer, and calculate errors based on labels. In this
                        case, the epsilon input is not used (may/should be null).
                        If false: calculate backprop gradients</dd>
<dt><span class="strong">Returns:</span></dt><dd>Gradients and the error (epsilon) at the input</dd></dl>
</li>
</ul>
<a name="doTruncatedBPTT(INDArray, INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>doTruncatedBPTT</h4>
<pre>protected&nbsp;void&nbsp;doTruncatedBPTT(INDArray&nbsp;input,
                   INDArray&nbsp;labels)</pre>
</li>
</ul>
<a name="updateRnnStateWithTBPTTState()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>updateRnnStateWithTBPTTState</h4>
<pre>protected&nbsp;void&nbsp;updateRnnStateWithTBPTTState()</pre>
</li>
</ul>
<a name="truncatedBPTTGradient()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>truncatedBPTTGradient</h4>
<pre>protected&nbsp;void&nbsp;truncatedBPTTGradient()</pre>
<div class="block">Equivalent to backprop(), but calculates gradient for truncated BPTT instead.</div>
</li>
</ul>
<a name="getListeners()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getListeners</h4>
<pre>public&nbsp;java.util.Collection&lt;<a href="../../../../org/deeplearning4j/optimize/api/IterationListener.html" title="interface in org.deeplearning4j.optimize.api">IterationListener</a>&gt;&nbsp;getListeners()</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#getListeners()">Layer</a></code></strong></div>
<div class="block">Get the iteration listeners for this layer.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#getListeners()">getListeners</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="strong">Returns:</span></dt><dd></dd></dl>
</li>
</ul>
<a name="setListeners(java.util.Collection)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setListeners</h4>
<pre>public&nbsp;void&nbsp;setListeners(java.util.Collection&lt;<a href="../../../../org/deeplearning4j/optimize/api/IterationListener.html" title="interface in org.deeplearning4j.optimize.api">IterationListener</a>&gt;&nbsp;listeners)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#setListeners(java.util.Collection)">Layer</a></code></strong></div>
<div class="block">Set the iteration listeners for this layer.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#setListeners(java.util.Collection)">setListeners</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
</dl>
</li>
</ul>
<a name="setListeners(org.deeplearning4j.optimize.api.IterationListener...)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setListeners</h4>
<pre>public&nbsp;void&nbsp;setListeners(<a href="../../../../org/deeplearning4j/optimize/api/IterationListener.html" title="interface in org.deeplearning4j.optimize.api">IterationListener</a>...&nbsp;listeners)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#setListeners(org.deeplearning4j.optimize.api.IterationListener...)">Layer</a></code></strong></div>
<div class="block">Set the iteration listeners for this layer.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#setListeners(org.deeplearning4j.optimize.api.IterationListener...)">setListeners</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
</dl>
</li>
</ul>
<a name="finetune()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>finetune</h4>
<pre>public&nbsp;void&nbsp;finetune()</pre>
<div class="block">Run SGD based on the given labels</div>
</li>
</ul>
<a name="predict(INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>predict</h4>
<pre>public&nbsp;int[]&nbsp;predict(INDArray&nbsp;d)</pre>
<div class="block">Returns the predictions for each example in the dataset</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html#predict(INDArray)">predict</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html" title="interface in org.deeplearning4j.nn.api">Classifier</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>d</code> - the matrix to predict</dd>
<dt><span class="strong">Returns:</span></dt><dd>the prediction for the dataset</dd></dl>
</li>
</ul>
<a name="labelProbabilities(INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>labelProbabilities</h4>
<pre>public&nbsp;INDArray&nbsp;labelProbabilities(INDArray&nbsp;examples)</pre>
<div class="block">Returns the probabilities for each label
 for each example row wise</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html#labelProbabilities(INDArray)">labelProbabilities</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html" title="interface in org.deeplearning4j.nn.api">Classifier</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>examples</code> - the examples to classify (one example in each row)</dd>
<dt><span class="strong">Returns:</span></dt><dd>the likelihoods of each example and each label</dd></dl>
</li>
</ul>
<a name="fit(INDArray, INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>fit</h4>
<pre>public&nbsp;void&nbsp;fit(INDArray&nbsp;data,
       INDArray&nbsp;labels)</pre>
<div class="block">Fit the model</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html#fit(INDArray,%20INDArray)">fit</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html" title="interface in org.deeplearning4j.nn.api">Classifier</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>data</code> - the examples to classify (one example in each row)</dd><dd><code>labels</code> - the example labels(a binary outcome matrix)</dd></dl>
</li>
</ul>
<a name="fit(INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>fit</h4>
<pre>public&nbsp;void&nbsp;fit(INDArray&nbsp;data)</pre>
<div class="block">Fit the unsupervised model</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html#fit(DataSetIterator)">fit</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html" title="interface in org.deeplearning4j.nn.api">Classifier</a></code></dd>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#fit(INDArray)">fit</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>data</code> - the examples to classify (one example in each row)</dd></dl>
</li>
</ul>
<a name="iterate(INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>iterate</h4>
<pre>public&nbsp;void&nbsp;iterate(INDArray&nbsp;input)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#iterate(INDArray)">Model</a></code></strong></div>
<div class="block">Run one iteration</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#iterate(INDArray)">iterate</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>input</code> - the input to iterate on</dd></dl>
</li>
</ul>
<a name="fit(org.nd4j.linalg.dataset.api.DataSet)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>fit</h4>
<pre>public&nbsp;void&nbsp;fit(org.nd4j.linalg.dataset.api.DataSet&nbsp;data)</pre>
<div class="block">Fit the model</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html#fit(DataSetIterator)">fit</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html" title="interface in org.deeplearning4j.nn.api">Classifier</a></code></dd>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#fit(INDArray)">fit</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>data</code> - the data to train on</dd></dl>
</li>
</ul>
<a name="fit(INDArray, int[])">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>fit</h4>
<pre>public&nbsp;void&nbsp;fit(INDArray&nbsp;examples,
       int[]&nbsp;labels)</pre>
<div class="block">Fit the model</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html#fit(INDArray,%20INDArray)">fit</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html" title="interface in org.deeplearning4j.nn.api">Classifier</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>examples</code> - the examples to classify (one example in each row)</dd><dd><code>labels</code> - the labels for each example (the number of labels must match</dd></dl>
</li>
</ul>
<a name="output(INDArray, org.deeplearning4j.nn.api.Layer.TrainingMode)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>output</h4>
<pre>public&nbsp;INDArray&nbsp;output(INDArray&nbsp;input,
              <a href="../../../../org/deeplearning4j/nn/api/Layer.TrainingMode.html" title="enum in org.deeplearning4j.nn.api">Layer.TrainingMode</a>&nbsp;train)</pre>
<div class="block">Label the probabilities of the input</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>input</code> - the input to label</dd><dd><code>train</code> - whether the output
             is test or train. This mainly
             affect hyper parameters such as
             drop out where certain things should
             be applied with activations</dd>
<dt><span class="strong">Returns:</span></dt><dd>a vector of probabilities
 given each label.
 <p>
 This is typically of the form:
 [0.5, 0.5] or some other probability distribution summing to one</dd></dl>
</li>
</ul>
<a name="output(INDArray, boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>output</h4>
<pre>public&nbsp;INDArray&nbsp;output(INDArray&nbsp;input,
              boolean&nbsp;train)</pre>
<div class="block">Label the probabilities of the input</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>input</code> - the input to label</dd><dd><code>train</code> - whether the output
             is test or train. This mainly
             affect hyper parameters such as
             drop out where certain things should
             be applied with activations</dd>
<dt><span class="strong">Returns:</span></dt><dd>a vector of probabilities
 given each label.
 <p>
 This is typically of the form:
 [0.5, 0.5] or some other probability distribution summing to one</dd></dl>
</li>
</ul>
<a name="output(INDArray, boolean, INDArray, INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>output</h4>
<pre>public&nbsp;INDArray&nbsp;output(INDArray&nbsp;input,
              boolean&nbsp;train,
              INDArray&nbsp;featuresMask,
              INDArray&nbsp;labelsMask)</pre>
<div class="block">Calculate the output of the network, with masking arrays. The masking arrays are used in situations such
 as one-to-many and many-to-one recurrent neural network (RNN) designs, as well as for supporting time series
 of varying lengths within the same minibatch.</div>
</li>
</ul>
<a name="output(INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>output</h4>
<pre>public&nbsp;INDArray&nbsp;output(INDArray&nbsp;input)</pre>
<div class="block">Label the probabilities of the input</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>input</code> - the input to label</dd>
<dt><span class="strong">Returns:</span></dt><dd>a vector of probabilities
 given each label.
 <p>
 This is typically of the form:
 [0.5, 0.5] or some other probability distribution summing to one</dd></dl>
</li>
</ul>
<a name="reconstruct(INDArray, int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>reconstruct</h4>
<pre>public&nbsp;INDArray&nbsp;reconstruct(INDArray&nbsp;x,
                   int&nbsp;layerNum)</pre>
<div class="block">Reconstructs the input.
 This is equivalent functionality to a
 deep autoencoder.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>x</code> - the input to transform</dd><dd><code>layerNum</code> - the layer to output for encoding</dd>
<dt><span class="strong">Returns:</span></dt><dd>a reconstructed matrix
 relative to the size of the last hidden layer.
 This is great for data compression and visualizing
 high dimensional data (or just doing dimensionality reduction).
 <p>
 This is typically of the form:
 [0.5, 0.5] or some other probability distribution summing to one</dd></dl>
</li>
</ul>
<a name="printConfiguration()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>printConfiguration</h4>
<pre>public&nbsp;void&nbsp;printConfiguration()</pre>
<div class="block">Prints the configuration</div>
</li>
</ul>
<a name="update(org.deeplearning4j.nn.multilayer.MultiLayerNetwork)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>update</h4>
<pre>public&nbsp;void&nbsp;update(<a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html" title="class in org.deeplearning4j.nn.multilayer">MultiLayerNetwork</a>&nbsp;network)</pre>
<div class="block">Assigns the parameters of this model to the ones specified by this
 network. This is used in loading from input streams, factory methods, etc</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>network</code> - the network to getFromOrigin parameters from</dd></dl>
</li>
</ul>
<a name="f1Score(INDArray, INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>f1Score</h4>
<pre>public&nbsp;double&nbsp;f1Score(INDArray&nbsp;input,
             INDArray&nbsp;labels)</pre>
<div class="block">Sets the input and labels and returns a score for the prediction
 wrt true labels</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html#f1Score(INDArray,%20INDArray)">f1Score</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html" title="interface in org.deeplearning4j.nn.api">Classifier</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>input</code> - the input to score</dd><dd><code>labels</code> - the true labels</dd>
<dt><span class="strong">Returns:</span></dt><dd>the score for the given input,label pairs</dd></dl>
</li>
</ul>
<a name="numLabels()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>numLabels</h4>
<pre>public&nbsp;int&nbsp;numLabels()</pre>
<div class="block">Returns the number of possible labels</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html#numLabels()">numLabels</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html" title="interface in org.deeplearning4j.nn.api">Classifier</a></code></dd>
<dt><span class="strong">Returns:</span></dt><dd>the number of possible labels for this classifier</dd></dl>
</li>
</ul>
<a name="score(DataSet)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>score</h4>
<pre>public&nbsp;double&nbsp;score(DataSet&nbsp;data)</pre>
<div class="block">Sets the input and labels and returns a score for the prediction with respect to the true labels<br>
 This is equivalent to <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#score(DataSet,%20boolean)"><code>score(DataSet, boolean)</code></a> with training==true.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>data</code> - the data to score</dd>
<dt><span class="strong">Returns:</span></dt><dd>the score for the given input,label pairs</dd><dt><span class="strong">See Also:</span></dt><dd><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#score(DataSet,%20boolean)"><code>score(DataSet, boolean)</code></a></dd></dl>
</li>
</ul>
<a name="score(DataSet, boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>score</h4>
<pre>public&nbsp;double&nbsp;score(DataSet&nbsp;data,
           boolean&nbsp;training)</pre>
<div class="block">Calculate the score (loss function) of the prediction with respect to the true labels<br></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>data</code> - data to calculate score for</dd><dd><code>training</code> - If true: score during training. If false: score at test time. This can affect the application of
                 certain features, such as dropout and dropconnect (which are applied at training time only)</dd>
<dt><span class="strong">Returns:</span></dt><dd>the score (value of the loss function)</dd></dl>
</li>
</ul>
<a name="fit()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>fit</h4>
<pre>public&nbsp;void&nbsp;fit()</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#fit()">Model</a></code></strong></div>
<div class="block">All models have a fit method</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#fit()">fit</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="update(INDArray, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>update</h4>
<pre>public&nbsp;void&nbsp;update(INDArray&nbsp;gradient,
          java.lang.String&nbsp;paramType)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#update(INDArray,%20java.lang.String)">Model</a></code></strong></div>
<div class="block">Perform one update  applying the gradient</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#update(INDArray,%20java.lang.String)">update</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#update(INDArray,%20java.lang.String)">update</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>gradient</code> - the gradient to apply</dd></dl>
</li>
</ul>
<a name="score()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>score</h4>
<pre>public&nbsp;double&nbsp;score()</pre>
<div class="block">Score of the model (relative to the objective function)</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#score()">score</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="strong">Returns:</span></dt><dd>the score of the model (relative to the objective function)</dd></dl>
</li>
</ul>
<a name="computeGradientAndScore()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>computeGradientAndScore</h4>
<pre>public&nbsp;void&nbsp;computeGradientAndScore()</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#computeGradientAndScore()">Model</a></code></strong></div>
<div class="block">Update the score</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#computeGradientAndScore()">computeGradientAndScore</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="accumulateScore(double)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>accumulateScore</h4>
<pre>public&nbsp;void&nbsp;accumulateScore(double&nbsp;accum)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#accumulateScore(double)">Model</a></code></strong></div>
<div class="block">Sets a rolling tally for the score. This is useful for mini batch learning when
 you are accumulating error across a dataset.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#accumulateScore(double)">accumulateScore</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>accum</code> - the amount to accum</dd></dl>
</li>
</ul>
<a name="clear()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>clear</h4>
<pre>public&nbsp;void&nbsp;clear()</pre>
<div class="block">Clear the inputs. Clears optimizer state.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#clear()">clear</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="score(INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>score</h4>
<pre>@Deprecated
public&nbsp;double&nbsp;score(INDArray&nbsp;param)</pre>
<div class="block"><span class="strong">Deprecated.</span>&nbsp;</div>
<div class="block">(Deprecated)
 Score of the model (relative to the objective function)</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>param</code> - the current parameters</dd>
<dt><span class="strong">Returns:</span></dt><dd>the score of the model (relative to the objective function)</dd></dl>
</li>
</ul>
<a name="merge(org.deeplearning4j.nn.api.Layer, int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>merge</h4>
<pre>public&nbsp;void&nbsp;merge(<a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>&nbsp;layer,
         int&nbsp;batchSize)</pre>
<div class="block">Averages the given logistic regression
 from a mini batch in to this one</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#merge(org.deeplearning4j.nn.api.Layer,%20int)">merge</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>layer</code> - the logistic regression to average in to this one</dd><dd><code>batchSize</code> - the batch size</dd></dl>
</li>
</ul>
<a name="merge(org.deeplearning4j.nn.multilayer.MultiLayerNetwork, int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>merge</h4>
<pre>public&nbsp;void&nbsp;merge(<a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html" title="class in org.deeplearning4j.nn.multilayer">MultiLayerNetwork</a>&nbsp;network,
         int&nbsp;batchSize)</pre>
<div class="block">Merges this network with the other one.
 This is a weight averaging with the update of:
 a += b - a / n
 where a is a matrix on the network
 b is the incoming matrix and n
 is the batch size.
 This update is performed across the network neuralNets
 as well as hidden neuralNets and logistic neuralNets</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>network</code> - the network to merge with</dd><dd><code>batchSize</code> - the batch size (number of training examples)
                  to average by</dd></dl>
</li>
</ul>
<a name="setInput(INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setInput</h4>
<pre>public&nbsp;void&nbsp;setInput(INDArray&nbsp;input)</pre>
<div class="block">Note that if input isn't null
 and the neuralNets are null, this is a way
 of initializing the neural network</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#setInput(INDArray)">setInput</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>input</code> - </dd></dl>
</li>
</ul>
<a name="getOutputLayer()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getOutputLayer</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>&nbsp;getOutputLayer()</pre>
<div class="block">Get the output layer</div>
<dl><dt><span class="strong">Returns:</span></dt><dd></dd></dl>
</li>
</ul>
<a name="setParameters(INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setParameters</h4>
<pre>public&nbsp;void&nbsp;setParameters(INDArray&nbsp;params)</pre>
<div class="block">Sets parameters for the model.
 This is used to manipulate the weights and biases across
 all neuralNets (including the output layer)</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>params</code> - a parameter vector equal 1,numParameters</dd></dl>
</li>
</ul>
<a name="applyLearningRateScoreDecay()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>applyLearningRateScoreDecay</h4>
<pre>public&nbsp;void&nbsp;applyLearningRateScoreDecay()</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#applyLearningRateScoreDecay()">Model</a></code></strong></div>
<div class="block">Update learningRate using for this model.
 Use the learningRateScoreBasedDecay to adapt the score
 if the Eps termination condition is met</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#applyLearningRateScoreDecay()">applyLearningRateScoreDecay</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="feedForwardR(java.util.List, INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>feedForwardR</h4>
<pre>public&nbsp;java.util.List&lt;INDArray&gt;&nbsp;feedForwardR(java.util.List&lt;INDArray&gt;&nbsp;acts,
                                    INDArray&nbsp;v)</pre>
<div class="block">Feed forward with the r operator</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>v</code> - the v for the r operator</dd>
<dt><span class="strong">Returns:</span></dt><dd>the activations based on the r operator</dd></dl>
</li>
</ul>
<a name="backPropGradientR(INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>backPropGradientR</h4>
<pre>protected&nbsp;java.util.List&lt;<a href="../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;INDArray,INDArray&gt;&gt;&nbsp;backPropGradientR(INDArray&nbsp;v)</pre>
<div class="block">Do a back prop iteration.
 This involves computing the activations, tracking the last neuralNets weights
 to revert to in case of convergence, the learning rate being used to iterate
 and the current epoch</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>v</code> - the v in gaussian newton vector g * v</dd>
<dt><span class="strong">Returns:</span></dt><dd>whether the training should converge or not</dd></dl>
</li>
</ul>
<a name="getDefaultConfiguration()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getDefaultConfiguration</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/conf/NeuralNetConfiguration.html" title="class in org.deeplearning4j.nn.conf">NeuralNetConfiguration</a>&nbsp;getDefaultConfiguration()</pre>
</li>
</ul>
<a name="getLabels()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLabels</h4>
<pre>public&nbsp;INDArray&nbsp;getLabels()</pre>
</li>
</ul>
<a name="getInput()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getInput</h4>
<pre>public&nbsp;INDArray&nbsp;getInput()</pre>
</li>
</ul>
<a name="setLabels(INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setLabels</h4>
<pre>public&nbsp;void&nbsp;setLabels(INDArray&nbsp;labels)</pre>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>labels</code> - </dd></dl>
</li>
</ul>
<a name="getnLayers()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getnLayers</h4>
<pre>public&nbsp;int&nbsp;getnLayers()</pre>
<div class="block">Get the number of layers in the network</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>the number of layers in the network</dd></dl>
</li>
</ul>
<a name="getLayers()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLayers</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>[]&nbsp;getLayers()</pre>
<dl><dt><span class="strong">Returns:</span></dt><dd></dd></dl>
</li>
</ul>
<a name="getLayer(int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLayer</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>&nbsp;getLayer(int&nbsp;i)</pre>
</li>
</ul>
<a name="getLayer(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLayer</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>&nbsp;getLayer(java.lang.String&nbsp;name)</pre>
</li>
</ul>
<a name="getLayerNames()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLayerNames</h4>
<pre>public&nbsp;java.util.List&lt;java.lang.String&gt;&nbsp;getLayerNames()</pre>
</li>
</ul>
<a name="setLayers(org.deeplearning4j.nn.api.Layer[])">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setLayers</h4>
<pre>public&nbsp;void&nbsp;setLayers(<a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>[]&nbsp;layers)</pre>
</li>
</ul>
<a name="getMask()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getMask</h4>
<pre>public&nbsp;INDArray&nbsp;getMask()</pre>
</li>
</ul>
<a name="setMask(INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setMask</h4>
<pre>public&nbsp;void&nbsp;setMask(INDArray&nbsp;mask)</pre>
</li>
</ul>
<a name="error(INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>error</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>&nbsp;error(INDArray&nbsp;errorSignal)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#error(INDArray)">Layer</a></code></strong></div>
<div class="block">Calculate error with respect to the
 current layer.

 This gradient will contain the error signal</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#error(INDArray)">error</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>errorSignal</code> - the gradient for the forward layer
              If this is the final layer, it will start
              with the error from the output.
              This is on the user to initialize.</dd>
<dt><span class="strong">Returns:</span></dt><dd>the gradient wrt the parameters
 on the current layer</dd></dl>
</li>
</ul>
<a name="type()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>type</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/api/Layer.Type.html" title="enum in org.deeplearning4j.nn.api">Layer.Type</a>&nbsp;type()</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#type()">Layer</a></code></strong></div>
<div class="block">Returns the layer type</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#type()">type</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="strong">Returns:</span></dt><dd></dd></dl>
</li>
</ul>
<a name="derivativeActivation(INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>derivativeActivation</h4>
<pre>public&nbsp;INDArray&nbsp;derivativeActivation(INDArray&nbsp;input)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#derivativeActivation(INDArray)">Layer</a></code></strong></div>
<div class="block">Take the derivative of the given input
 based on the activation</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#derivativeActivation(INDArray)">derivativeActivation</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>input</code> - the input to take the derivative of</dd>
<dt><span class="strong">Returns:</span></dt><dd>the derivative of the action</dd></dl>
</li>
</ul>
<a name="calcGradient(org.deeplearning4j.nn.gradient.Gradient, INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>calcGradient</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>&nbsp;calcGradient(<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>&nbsp;layerError,
                    INDArray&nbsp;activation)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#calcGradient(org.deeplearning4j.nn.gradient.Gradient,%20INDArray)">Layer</a></code></strong></div>
<div class="block">Calculate the gradient</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#calcGradient(org.deeplearning4j.nn.gradient.Gradient,%20INDArray)">calcGradient</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>layerError</code> - the layer error</dd>
<dt><span class="strong">Returns:</span></dt><dd>the gradient</dd></dl>
</li>
</ul>
<a name="preOutput(INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>preOutput</h4>
<pre>public&nbsp;INDArray&nbsp;preOutput(INDArray&nbsp;x)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#preOutput(INDArray)">Layer</a></code></strong></div>
<div class="block">Raw activations</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#preOutput(INDArray)">preOutput</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>x</code> - the input to transform</dd>
<dt><span class="strong">Returns:</span></dt><dd>the raw activation
 for this layer</dd></dl>
</li>
</ul>
<a name="preOutput(INDArray, org.deeplearning4j.nn.api.Layer.TrainingMode)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>preOutput</h4>
<pre>public&nbsp;INDArray&nbsp;preOutput(INDArray&nbsp;x,
                 <a href="../../../../org/deeplearning4j/nn/api/Layer.TrainingMode.html" title="enum in org.deeplearning4j.nn.api">Layer.TrainingMode</a>&nbsp;training)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#preOutput(INDArray,%20org.deeplearning4j.nn.api.Layer.TrainingMode)">Layer</a></code></strong></div>
<div class="block">Raw activations</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#preOutput(INDArray,%20org.deeplearning4j.nn.api.Layer.TrainingMode)">preOutput</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>x</code> - the input to transform</dd>
<dt><span class="strong">Returns:</span></dt><dd>the raw activation
 for this layer</dd></dl>
</li>
</ul>
<a name="activate(org.deeplearning4j.nn.api.Layer.TrainingMode)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>activate</h4>
<pre>public&nbsp;INDArray&nbsp;activate(<a href="../../../../org/deeplearning4j/nn/api/Layer.TrainingMode.html" title="enum in org.deeplearning4j.nn.api">Layer.TrainingMode</a>&nbsp;training)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#activate(org.deeplearning4j.nn.api.Layer.TrainingMode)">Layer</a></code></strong></div>
<div class="block">Trigger an activation with the last specified input</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#activate(org.deeplearning4j.nn.api.Layer.TrainingMode)">activate</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>training</code> - training or test mode</dd>
<dt><span class="strong">Returns:</span></dt><dd>the activation of the last specified input</dd></dl>
</li>
</ul>
<a name="activate(INDArray, org.deeplearning4j.nn.api.Layer.TrainingMode)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>activate</h4>
<pre>public&nbsp;INDArray&nbsp;activate(INDArray&nbsp;input,
                <a href="../../../../org/deeplearning4j/nn/api/Layer.TrainingMode.html" title="enum in org.deeplearning4j.nn.api">Layer.TrainingMode</a>&nbsp;training)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#activate(INDArray,%20org.deeplearning4j.nn.api.Layer.TrainingMode)">Layer</a></code></strong></div>
<div class="block">Initialize the layer with the given input
 and return the activation for this layer
 given this input</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#activate(INDArray,%20org.deeplearning4j.nn.api.Layer.TrainingMode)">activate</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>input</code> - the input to use</dd><dd><code>training</code> - train or test mode</dd>
<dt><span class="strong">Returns:</span></dt><dd></dd></dl>
</li>
</ul>
<a name="transpose()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>transpose</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>&nbsp;transpose()</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#transpose()">Layer</a></code></strong></div>
<div class="block">Return a transposed copy of the weights/bias
 (this means reverse the number of inputs and outputs on the weights)</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#transpose()">transpose</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="strong">Returns:</span></dt><dd>the transposed layer</dd></dl>
</li>
</ul>
<a name="backpropGradient(INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>backpropGradient</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>,INDArray&gt;&nbsp;backpropGradient(INDArray&nbsp;epsilon)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#backpropGradient(INDArray)">Layer</a></code></strong></div>
<div class="block">Calculate the gradient relative to the error in the next layer</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#backpropGradient(INDArray)">backpropGradient</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>epsilon</code> - w^(L+1)*delta^(L+1). Or, equiv: dC/da, i.e., (dC/dz)/(dz/da) = dC/da, where C 
        is cost function a=sigma(z) is activation.</dd>
<dt><span class="strong">Returns:</span></dt><dd>Pair<Gradient,INDArray> where Gradient is gradient for this layer, INDArray is epsilon needed by next
  layer, but before element-wise multiply by sigmaPrime(z). So for standard feed-forward layer, if this layer is
  L, then return.getSecond() == (w^(L)*(delta^(L))^T)^T</dd></dl>
</li>
</ul>
<a name="setIndex(int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setIndex</h4>
<pre>public&nbsp;void&nbsp;setIndex(int&nbsp;index)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#setIndex(int)">Layer</a></code></strong></div>
<div class="block">Set the layer index.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#setIndex(int)">setIndex</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
</dl>
</li>
</ul>
<a name="getIndex()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getIndex</h4>
<pre>public&nbsp;int&nbsp;getIndex()</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#getIndex()">Layer</a></code></strong></div>
<div class="block">Get the layer index.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#getIndex()">getIndex</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
</dl>
</li>
</ul>
<a name="calcL2()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>calcL2</h4>
<pre>public&nbsp;double&nbsp;calcL2()</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#calcL2()">Layer</a></code></strong></div>
<div class="block">Calculate the l2 regularization term<br>
 0.0 if regularization is not used. Or 0.5 * l2Coeff * l2Magnitude otherwise.<br>
 Note that this does not divide by mini-batch size</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#calcL2()">calcL2</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="strong">Returns:</span></dt><dd>the l2 regularization term for this layer.</dd></dl>
</li>
</ul>
<a name="calcL1()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>calcL1</h4>
<pre>public&nbsp;double&nbsp;calcL1()</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#calcL1()">Layer</a></code></strong></div>
<div class="block">Calculate the l1 regularization term<br>
 0.0 if regularization is not used. Or l1Coeff * l1Magnitude otherwise.<br>
 Note that this does not divide by mini-batch size</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#calcL1()">calcL1</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="strong">Returns:</span></dt><dd>the l1 regularization term for this layer.</dd></dl>
</li>
</ul>
<a name="update(org.deeplearning4j.nn.gradient.Gradient)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>update</h4>
<pre>public&nbsp;void&nbsp;update(<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>&nbsp;gradient)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#update(org.deeplearning4j.nn.gradient.Gradient)">Layer</a></code></strong></div>
<div class="block">Update layer weights and biases with gradient change</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#update(org.deeplearning4j.nn.gradient.Gradient)">update</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
</dl>
</li>
</ul>
<a name="preOutput(INDArray, boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>preOutput</h4>
<pre>public&nbsp;INDArray&nbsp;preOutput(INDArray&nbsp;x,
                 boolean&nbsp;training)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#preOutput(INDArray,%20boolean)">Layer</a></code></strong></div>
<div class="block">Raw activations</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#preOutput(INDArray,%20boolean)">preOutput</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>x</code> - the input to transform</dd>
<dt><span class="strong">Returns:</span></dt><dd>the raw activation
 for this layer</dd></dl>
</li>
</ul>
<a name="activate(boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>activate</h4>
<pre>public&nbsp;INDArray&nbsp;activate(boolean&nbsp;training)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#activate(boolean)">Layer</a></code></strong></div>
<div class="block">Trigger an activation with the last specified input</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#activate(boolean)">activate</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>training</code> - training or test mode</dd>
<dt><span class="strong">Returns:</span></dt><dd>the activation of the last specified input</dd></dl>
</li>
</ul>
<a name="activate(INDArray, boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>activate</h4>
<pre>public&nbsp;INDArray&nbsp;activate(INDArray&nbsp;input,
                boolean&nbsp;training)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#activate(INDArray,%20boolean)">Layer</a></code></strong></div>
<div class="block">Initialize the layer with the given input
 and return the activation for this layer
 given this input</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#activate(INDArray,%20boolean)">activate</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>input</code> - the input to use</dd><dd><code>training</code> - train or test mode</dd>
<dt><span class="strong">Returns:</span></dt><dd></dd></dl>
</li>
</ul>
<a name="setInputMiniBatchSize(int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setInputMiniBatchSize</h4>
<pre>public&nbsp;void&nbsp;setInputMiniBatchSize(int&nbsp;size)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#setInputMiniBatchSize(int)">Layer</a></code></strong></div>
<div class="block">Set current/last input mini-batch size.<br>
 Used for score and gradient calculations. Mini batch size may be different from
 getInput().size(0) due to reshaping operations - for example, when using RNNs with
 DenseLayer and OutputLayer. Called automatically during forward pass.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#setInputMiniBatchSize(int)">setInputMiniBatchSize</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
</dl>
</li>
</ul>
<a name="getInputMiniBatchSize()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getInputMiniBatchSize</h4>
<pre>public&nbsp;int&nbsp;getInputMiniBatchSize()</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#getInputMiniBatchSize()">Layer</a></code></strong></div>
<div class="block">Get current/last input mini-batch size, as set by setInputMiniBatchSize(int)</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#getInputMiniBatchSize()">getInputMiniBatchSize</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="strong">See Also:</span></dt><dd><a href="../../../../org/deeplearning4j/nn/api/Layer.html#setInputMiniBatchSize(int)"><code>Layer.setInputMiniBatchSize(int)</code></a></dd></dl>
</li>
</ul>
<a name="setMaskArray(INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setMaskArray</h4>
<pre>public&nbsp;void&nbsp;setMaskArray(INDArray&nbsp;maskArray)</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#setMaskArray(INDArray)">setMaskArray</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
</dl>
</li>
</ul>
<a name="rnnTimeStep(INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>rnnTimeStep</h4>
<pre>public&nbsp;INDArray&nbsp;rnnTimeStep(INDArray&nbsp;input)</pre>
<div class="block">If this MultiLayerNetwork contains one or more RNN layers: conduct forward pass (prediction)
 but using previous stored state for any RNN layers. The activations for the final step are
 also stored in the RNN layers for use next time rnnTimeStep() is called.<br>
 This method can be used to generate output one or more steps at a time instead of always having to do
 forward pass from t=0. Example uses are for streaming data, and for generating samples from network output
 one step at a time (where samples are then fed back into the network as input)<br>
 If no previous state is present in RNN layers (i.e., initially or after calling rnnClearPreviousState()),
 the default initialization (usually 0) is used.<br>
 Supports mini-batch (i.e., multiple predictions/forward pass in parallel) as well as for single examples.<br></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>input</code> - Input to network. May be for one or multiple time steps. For single time step:
  input has shape [miniBatchSize,inputSize] or [miniBatchSize,inputSize,1]. miniBatchSize=1 for single example.<br>
  For multiple time steps: [miniBatchSize,inputSize,inputTimeSeriesLength]</dd>
<dt><span class="strong">Returns:</span></dt><dd>Output activations. If output is RNN layer (such as RnnOutputLayer): if input has shape [miniBatchSize,inputSize]
 i.e., is 2d, output has shape [miniBatchSize,outputSize] (i.e., also 2d).<br>
 Otherwise output is 3d [miniBatchSize,outputSize,inputTimeSeriesLength] when using RnnOutputLayer.</dd></dl>
</li>
</ul>
<a name="rnnGetPreviousState(int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>rnnGetPreviousState</h4>
<pre>public&nbsp;java.util.Map&lt;java.lang.String,INDArray&gt;&nbsp;rnnGetPreviousState(int&nbsp;layer)</pre>
<div class="block">Get the state of the RNN layer, as used in rnnTimeStep().</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>layer</code> - Number/index of the layer.</dd>
<dt><span class="strong">Returns:</span></dt><dd>Hidden state, or null if layer is not an RNN layer</dd></dl>
</li>
</ul>
<a name="rnnSetPreviousState(int, java.util.Map)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>rnnSetPreviousState</h4>
<pre>public&nbsp;void&nbsp;rnnSetPreviousState(int&nbsp;layer,
                       java.util.Map&lt;java.lang.String,INDArray&gt;&nbsp;state)</pre>
<div class="block">Set the state of the RNN layer.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>layer</code> - The number/index of the layer.</dd><dd><code>state</code> - The state to set the specified layer to</dd></dl>
</li>
</ul>
<a name="rnnClearPreviousState()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>rnnClearPreviousState</h4>
<pre>public&nbsp;void&nbsp;rnnClearPreviousState()</pre>
<div class="block">Clear the previous state of the RNN layers (if any).</div>
</li>
</ul>
<a name="rnnActivateUsingStoredState(INDArray, boolean, boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>rnnActivateUsingStoredState</h4>
<pre>public&nbsp;java.util.List&lt;INDArray&gt;&nbsp;rnnActivateUsingStoredState(INDArray&nbsp;input,
                                                   boolean&nbsp;training,
                                                   boolean&nbsp;storeLastForTBPTT)</pre>
<div class="block">Similar to rnnTimeStep and feedForward() methods. Difference here is that this method:<br>
 (a) like rnnTimeStep does forward pass using stored state for RNN layers, and<br>
 (b) unlike rnnTimeStep does not modify the RNN layer state<br>
 Therefore multiple calls to this method with the same input should have the same output.<br>
 Typically used during training only. Use rnnTimeStep for prediction/forward pass at test time.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>input</code> - Input to network</dd><dd><code>training</code> - Whether training or not</dd><dd><code>storeLastForTBPTT</code> - set to true if used as part of truncated BPTT training</dd>
<dt><span class="strong">Returns:</span></dt><dd>Activations for each layer (including input, as per feedforward() etc)</dd></dl>
</li>
</ul>
<a name="getUpdater()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getUpdater</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/api/Updater.html" title="interface in org.deeplearning4j.nn.api">Updater</a>&nbsp;getUpdater()</pre>
<div class="block">Get the updater for this MultiLayerNetwork</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>Updater for MultiLayerNetwork</dd></dl>
</li>
</ul>
<a name="setUpdater(org.deeplearning4j.nn.api.Updater)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setUpdater</h4>
<pre>public&nbsp;void&nbsp;setUpdater(<a href="../../../../org/deeplearning4j/nn/api/Updater.html" title="interface in org.deeplearning4j.nn.api">Updater</a>&nbsp;updater)</pre>
<div class="block">Set the updater for the MultiLayerNetwork</div>
</li>
</ul>
<a name="setLayerMaskArrays(INDArray, INDArray)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setLayerMaskArrays</h4>
<pre>public&nbsp;void&nbsp;setLayerMaskArrays(INDArray&nbsp;featuresMaskArray,
                      INDArray&nbsp;labelsMaskArray)</pre>
<div class="block">Set the mask arrays for features and labels. Mask arrays are typically used in situations such as one-to-many
 and many-to-one learning with recurrent neural networks, as well as for supporting time series of varying lengths
 within the same minibatch.<br>
 For example, with RNN data sets with input of shape [miniBatchSize,nIn,timeSeriesLength] and outputs of shape
 [miniBatchSize,nOut,timeSeriesLength], the features and mask arrays will have shape [miniBatchSize,timeSeriesLength]
 and contain values 0 or 1 at each element (to specify whether a given input/example is present - or merely padding -
 at a given time step).<br>
 <b>NOTE</b>: This method is not usually used directly. Instead, methods such as <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#feedForward(INDArray,%20INDArray,%20INDArray)"><code>feedForward(INDArray, INDArray, INDArray)</code></a>
 and <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#output(INDArray,%20boolean,%20INDArray,%20INDArray)"><code>output(INDArray, boolean, INDArray, INDArray)</code></a> handle setting of masking internally.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>featuresMaskArray</code> - Mask array for features (input)</dd><dd><code>labelsMaskArray</code> - Mask array for labels (output)</dd><dt><span class="strong">See Also:</span></dt><dd><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#clearLayerMaskArrays()"><code>clearLayerMaskArrays()</code></a></dd></dl>
</li>
</ul>
<a name="clearLayerMaskArrays()">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>clearLayerMaskArrays</h4>
<pre>public&nbsp;void&nbsp;clearLayerMaskArrays()</pre>
<div class="block">Remove the mask arrays from all layers.<br>
 See <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setLayerMaskArrays(INDArray,%20INDArray)"><code>setLayerMaskArrays(INDArray, INDArray)</code></a> for details on mask arrays.</div>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar_bottom">
<!--   -->
</a><a href="#skip-navbar_bottom" title="Skip navigation links"></a><a name="navbar_bottom_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-files/index-1.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/deeplearning4j/nn/multilayer/GravesLSTMOutputTest.html" title="class in org.deeplearning4j.nn.multilayer"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerTest.html" title="class in org.deeplearning4j.nn.multilayer"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html" target="_top">Frames</a></li>
<li><a href="MultiLayerNetwork.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li><a href="#field_summary">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li><a href="#field_detail">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
</body>
</html>
